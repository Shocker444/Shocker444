{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"g9AKVOxWJdB7"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import re\n","import string\n","import pathlib\n","from tensorflow import keras\n","from google.colab import drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4026,"status":"ok","timestamp":1660401971206,"user":{"displayName":"X Life","userId":"10647309832887347003"},"user_tz":-60},"id":"2jUjVo5IAwSI","outputId":"2a705e87-2dda-439c-aeb4-861b429f5c92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RrJuvA-ZO0_p"},"outputs":[],"source":["path = '/content/drive/MyDrive/stack_overflow'\n","data_dir = pathlib.Path(path)\n","data_dir = os.path.join(os.path.dirname(data_dir),  'stack_overflow')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1660401971211,"user":{"displayName":"X Life","userId":"10647309832887347003"},"user_tz":-60},"id":"fNpWzNUzGRO5","outputId":"79acd59e-5999-4091-bd49-f90f9ee99545"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['test', 'train', 'README.md']"]},"metadata":{},"execution_count":4}],"source":["os.listdir(data_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NS_7PjkQBOG7"},"outputs":[],"source":["train_dir = os.path.join(data_dir, 'train')\n","test_dir = os.path.join(data_dir, 'test')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1053,"status":"ok","timestamp":1660401972249,"user":{"displayName":"X Life","userId":"10647309832887347003"},"user_tz":-60},"id":"Yr_tuZEGB5-k","outputId":"9efd9fad-df3e-4828-c788-912e07761947"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8000 files belonging to 4 classes.\n","Using 7200 files for training.\n"]}],"source":["seed = 42\n","batch_size = 32\n","\n","train_ds = keras.utils.text_dataset_from_directory(\n","    train_dir,\n","    batch_size = batch_size,\n","    validation_split=0.1,\n","    subset = 'training',\n","    seed = seed\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N8yHkOjeDoJW"},"outputs":[],"source":["class_names = train_ds.class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3535,"status":"ok","timestamp":1660401975779,"user":{"displayName":"X Life","userId":"10647309832887347003"},"user_tz":-60},"id":"grc73KKJDs5U","outputId":"63122447-0e2b-44f9-f545-293aaf9038e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8000 files belonging to 4 classes.\n","Using 800 files for validation.\n"]}],"source":["validation_ds = keras.utils.text_dataset_from_directory(\n","    train_dir,\n","    batch_size = batch_size,\n","    validation_split = 0.1,\n","    subset = 'validation',\n","    seed = seed\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1660401975781,"user":{"displayName":"X Life","userId":"10647309832887347003"},"user_tz":-60},"id":"dSXqVRuAE8NM","outputId":"11d51fac-aa08-4e36-e85c-eec72f994a53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8002 files belonging to 4 classes.\n"]}],"source":["test_ds = keras.utils.text_dataset_from_directory(\n","    test_dir,\n","    batch_size = batch_size\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":969,"status":"ok","timestamp":1660401976733,"user":{"displayName":"X Life","userId":"10647309832887347003"},"user_tz":-60},"id":"9f74NjR3FeHg","outputId":"64dd897a-2bb9-4717-bc76-3abe7f3b1b72"},"outputs":[{"output_type":"stream","name":"stdout","text":["b'\"my tester is going to the wrong constructor i am new to programming so if i ask a question that can be easily fixed, please forgive me. my program has a tester class with a main. when i send that to my regularpolygon class, it sends it to the wrong constructor. i have two constructors. 1 without perameters..public regularpolygon().    {.       mynumsides = 5;.       mysidelength = 30;.    }//end default constructor...and my second, with perameters. ..public regularpolygon(int numsides, double sidelength).    {.        mynumsides = numsides;.        mysidelength = sidelength;.    }// end constructor...in my tester class i have these two lines:..regularpolygon shape = new regularpolygon(numsides, sidelength);.        shape.menu();...numsides and sidelength were declared and initialized earlier in the testing class...so what i want to happen, is the tester class sends numsides and sidelength to the second constructor and use it in that class. but it only uses the default constructor, which therefor ruins the whole rest of the program. can somebody help me?..for those of you who want to see more of my code: here you go..public double vertexangle().    {.        system.out.println(\"\"the vertex angle method: \"\" + mynumsides);// prints out 5.        system.out.println(\"\"the vertex angle method: \"\" + mysidelength); // prints out 30..        double vertexangle;.        vertexangle = ((mynumsides - 2.0) / mynumsides) * 180.0;.        return vertexangle;.    }//end method vertexangle..public void menu().{.    system.out.println(mynumsides); // prints out what the user puts in.    system.out.println(mysidelength); // prints out what the user puts in.    gotographic();.    calcr(mynumsides, mysidelength);.    calcr(mynumsides, mysidelength);.    print(); .}// end menu...this is my entire tester class:..public static void main(string[] arg).{.    int numsides;.    double sidelength;.    scanner keyboard = new scanner(system.in);..    system.out.println(\"\"welcome to the regular polygon program!\"\");.    system.out.println();..    system.out.print(\"\"enter the number of sides of the polygon ==&gt; \"\");.    numsides = keyboard.nextint();.    system.out.println();..    system.out.print(\"\"enter the side length of each side ==&gt; \"\");.    sidelength = keyboard.nextdouble();.    system.out.println();..    regularpolygon shape = new regularpolygon(numsides, sidelength);.    shape.menu();.}//end main...for testing it i sent it numsides 4 and sidelength 100.\"\\n'\n","b'\"blank code slow skin detection this code changes the color space to lab and using a threshold finds the skin area of an image. but it\\'s ridiculously slow. i don\\'t know how to make it faster ?    ..from colormath.color_objects import *..def skindetection(img, treshold=80, color=[255,20,147]):..    print img.shape.    res=img.copy().    for x in range(img.shape[0]):.        for y in range(img.shape[1]):.            rgbimg=rgbcolor(img[x,y,0],img[x,y,1],img[x,y,2]).            labimg=rgbimg.convert_to(\\'lab\\', debug=false).            if (labimg.lab_l &gt; treshold):.                res[x,y,:]=color.            else: .                res[x,y,:]=img[x,y,:]..    return res\"\\n'\n"]}],"source":["for test_batch, label_batch in train_ds.take(1):\n","  for i in range(2):\n","    print(test_batch[i].numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ifxv86qDGzHD"},"outputs":[],"source":["def custom_standardization(input_data):\n","  lowercase = tf.strings.lower(input_data)\n","  stripped_tags = tf.strings.regex_replace(lowercase, '\\n', '')\n","  return tf.strings.regex_replace(stripped_tags,\n","                                  '[%s]' % re.escape(string.punctuation),'')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iyfO62_1Ot2B"},"outputs":[],"source":["max_features = 10000\n","sequence_length = 250\n","\n","vectorize_layer = keras.layers.TextVectorization(\n","    standardize=custom_standardization,\n","    max_tokens=max_features,\n","    output_mode='int',\n","    output_sequence_length=sequence_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmcOZS_ag5_t"},"outputs":[],"source":["# Make a text-only dataset (without labels), then call adapt\n","train_text = train_ds.map(lambda x, y: x)\n","vectorize_layer.adapt(train_text)"]},{"cell_type":"code","source":["# creating a function to return the vectorized text \n","def vectorize(text, label):\n","  text = vectorize_layer(text)\n","  return text, label"],"metadata":{"id":"DqeTQ1InKLE4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oFRaIUzzkq7o"},"outputs":[],"source":["# mapping the function to the datasets\n","train = train_ds.map(vectorize)\n","validation = validation_ds.map(vectorize)\n","test = test_ds.map(vectorize)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3QaDiViTlDrd"},"outputs":[],"source":["# configuring the dataset for performance\n","Autotune = tf.data.AUTOTUNE\n","\n","train_batches = train.cache().shuffle(1000).prefetch(buffer_size=Autotune)\n","val_batches = validation.cache().prefetch(buffer_size=Autotune)\n","test_batches = test.cache().prefetch(buffer_size=Autotune)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"klMhlcWbFM_b","executionInfo":{"status":"ok","timestamp":1660402318423,"user_tz":-60,"elapsed":19201,"user":{"displayName":"X Life","userId":"10647309832887347003"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"49aa3750-d022-4159-ddce-e753797f9d02"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[ 682  140   31  534   18    3   17    2  123  534   18   54    6    2\n","  393   84    4  682    2  140   31   11   47   16 3109   50    1    1\n","    1    1 3174 4634    1    1    1    1    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0], shape=(250,), dtype=int64) tf.Tensor(0, shape=(), dtype=int32)\n"]}],"source":["for text, label in train_batches.take(1):\n","  for i in range(1):\n","    print(text[i], label[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R-NLdSEJhoD3"},"outputs":[],"source":["embedding_dim = 16\n","\n","model = keras.Sequential([\n","    keras.layers.Embedding(max_features + 1, embedding_dim),\n","    keras.layers.Dropout(0.2),\n","    keras.layers.GlobalAveragePooling1D(),\n","    keras.layers.Dropout(0.2),\n","    keras.layers.Dense(4)\n","])\n","\n","\n","model.compile(\n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer = 'adam',\n","    metrics = ['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"po3pcKBRnTuD","executionInfo":{"status":"ok","timestamp":1660402318432,"user_tz":-60,"elapsed":108,"user":{"displayName":"X Life","userId":"10647309832887347003"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0b79c5c-554c-4806-b83c-5f7f9d5b1286"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 16)          160016    \n","                                                                 \n"," dropout (Dropout)           (None, None, 16)          0         \n","                                                                 \n"," global_average_pooling1d (G  (None, 16)               0         \n"," lobalAveragePooling1D)                                          \n","                                                                 \n"," dropout_1 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense (Dense)               (None, 4)                 68        \n","                                                                 \n","=================================================================\n","Total params: 160,084\n","Trainable params: 160,084\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6pB7USjkL0T","executionInfo":{"status":"ok","timestamp":1660402457704,"user_tz":-60,"elapsed":139348,"user":{"displayName":"X Life","userId":"10647309832887347003"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc77c20e-9b50-4442-b318-0828ba3c5eff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","225/225 [==============================] - 91s 401ms/step - loss: 1.3793 - accuracy: 0.3529 - val_loss: 1.3692 - val_accuracy: 0.3900\n","Epoch 2/15\n","225/225 [==============================] - 2s 7ms/step - loss: 1.3501 - accuracy: 0.5122 - val_loss: 1.3265 - val_accuracy: 0.5175\n","Epoch 3/15\n","225/225 [==============================] - 2s 7ms/step - loss: 1.1294 - accuracy: 0.6575 - val_loss: 1.0898 - val_accuracy: 0.6938\n","Epoch 6/15\n","225/225 [==============================] - 1s 6ms/step - loss: 1.0442 - accuracy: 0.7038 - val_loss: 1.0116 - val_accuracy: 0.7175\n","Epoch 7/15\n","225/225 [==============================] - 1s 6ms/step - loss: 0.9672 - accuracy: 0.7310 - val_loss: 0.9430 - val_accuracy: 0.7325\n","Epoch 8/15\n","225/225 [==============================] - 1s 6ms/step - loss: 0.8989 - accuracy: 0.7486 - val_loss: 0.8792 - val_accuracy: 0.7513\n","Epoch 9/15\n","225/225 [==============================] - 2s 7ms/step - loss: 0.8389 - accuracy: 0.7688 - val_loss: 0.8269 - val_accuracy: 0.7638\n","Epoch 10/15\n","225/225 [==============================] - 1s 6ms/step - loss: 0.7870 - accuracy: 0.7807 - val_loss: 0.7835 - val_accuracy: 0.7625\n","Epoch 11/15\n","225/225 [==============================] - 1s 6ms/step - loss: 0.7415 - accuracy: 0.7928 - val_loss: 0.7495 - val_accuracy: 0.7700\n","Epoch 12/15\n","225/225 [==============================] - 2s 7ms/step - loss: 0.7023 - accuracy: 0.8067 - val_loss: 0.7098 - val_accuracy: 0.7788\n","Epoch 13/15\n","225/225 [==============================] - 1s 6ms/step - loss: 0.6694 - accuracy: 0.8128 - val_loss: 0.6824 - val_accuracy: 0.7850\n","Epoch 14/15\n","225/225 [==============================] - 1s 6ms/step - loss: 0.6335 - accuracy: 0.8253 - val_loss: 0.6555 - val_accuracy: 0.7950\n","Epoch 15/15\n","225/225 [==============================] - 2s 7ms/step - loss: 0.6084 - accuracy: 0.8299 - val_loss: 0.6332 - val_accuracy: 0.8025\n"]}],"source":["# training the model\n","num_epochs = 15\n","history = model.fit(\n","    train_batches,\n","    epochs = num_epochs,\n","    validation_data = val_batches)"]},{"cell_type":"code","source":["predictions = model.predict(test_batches, verbose=0)"],"metadata":{"id":"tEgehkiYgZwJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Exporting the model\n","export_model = keras.Sequential([\n","    vectorize_layer,\n","    model,\n","    keras.layers.Activation('softmax')\n","])\n","\n","export_model.compile(\n","    loss = 'sparse_categorical_crossentropy',\n","    optimizer = 'adam',\n","    metrics = ['accuracy']\n",")"],"metadata":{"id":"6GVOXunehn3K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the example below.\n","example = ['how to install practnlp tools how to install practnlptools in windows as there is no installation guidance in pypi? it would be very helpful also to know how to use srl tagger in there.']\n","predicted_example = export_model.predict(example)\n","print(class_names[np.argmax(predicted_example)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kflxlqTHxIpo","executionInfo":{"status":"ok","timestamp":1660411519177,"user_tz":-60,"elapsed":734,"user":{"displayName":"X Life","userId":"10647309832887347003"}},"outputId":"2fed38b6-5959-490f-bfdb-5a5840484533"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["python\n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"multiclass classification on stack overflow questions.ipynb","provenance":[],"authorship_tag":"ABX9TyP74EH62oiq9x3zTHwe4UVU"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}